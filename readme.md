# 并行算法学习笔记

<!-- 起因：nudt夏令营老师提问数独怎么求解的，是否使用gpu，因此后续学习cuda编程 -->

> 阅读材料：CUDA C编程权威指南（Professional CUDA C Programming）

***目录：***
- [并行算法学习笔记](#并行算法学习笔记)
  - [CH1 基于CUDA的异构并行计算](#ch1-基于cuda的异构并行计算)
    - [1.1 并行计算](#11-并行计算)
      - [1.1.1　串行编程和并行编程](#111串行编程和并行编程)
      - [1.1.2　并行性](#112并行性)
      - [1.1.3 计算机架构](#113-计算机架构)
    - [1.2 异构计算](#12-异构计算)
      - [1.2.1 异构架构](#121-异构架构)
    - [1.3 用GPU输出hello world](#13-用gpu输出hello-world)
    - [1.4 课后习题](#14-课后习题)
  - [CH2 CUDA 编程模型](#ch2-cuda-编程模型)
    - [2.1 CUDA编程模型概述](#21-cuda编程模型概述)
      - [2.1.1 CUDA编程模型](#211-cuda编程模型)
    - [2.1.2 内存管理](#212-内存管理)


## CH1 基于CUDA的异构并行计算

### 1.1 并行计算

并行计算通常涉及两个不同的计算技术领域：

- 计算机架构（硬件方面）
- 并行程序设计（软件方面）

#### 1.1.1　串行编程和并行编程

- 并行程序：包含并发执行任务的程序都是
- 相关性：如果一个任务处理的是另一个任务的输出，那么它们就是相关的，否则就是独立的。

#### 1.1.2　并行性

并行类型:

- 任务并行  许多任务或函数可以独立地、大规模地并行执行  重点在于利用多核系统对任务进行分配
- 数据并行(⭐)  同时处理许多数据  重点在于利用多核系统对数据进行分配

数据划分:

- 块划分：每个线程作用于一部分数据，通常这些数据具有相同大小
- 周期划分：每个线程作用于数据的多部分

#### 1.1.3 计算机架构

弗林分类法（指令和数据进入CPU的方式）:SISD, SIMD, MISD, MIMD

延迟：一个操作从开始到完成所需要的时间

带宽：单位时间内可处理的数据量

吞吐量：单位时间内成功处理的运算数量

框架分类（内存组织方式）：分布式内存的多节点系统、共享内存的多处理器系统

|芯片类型|分类|应用场景|描述|
|-|-|-|-|
|CPU|多核|控制密集型任务（动态工作负载，短序列的计算操作和不可预测）|CPU核心比较重，用来处理非常复杂的控制逻辑，以优化串行程序执行|
|GPU|众核|数据并行的计算密集型任务（计算任务主导的且带有简单控制流）|GPU核心较轻，用于优化具有简单控制逻辑的数据并行任务，注重并行程序的吞吐量|

### 1.2 异构计算

同构计算：同一架构下的一个或多个处理器来执行一个应用

异构计算：使用一个处理器架构来执行一个应用，为任务选择适合它的架构，使其最终对性能有所改进

#### 1.2.1 异构架构

一个异构应用包括两个部分：
- 主机代码
- 设备代码

GPU容量的两个重要特征：
- CUDA核心数量
- 内存大小

评估GPU的性能：
- 峰值计算性能，评估计算容量，通常定义为每秒能处理的单精度或双精度浮点运算的数量
- 内存带宽，从内存中读取或写入数据的比率

### 1.3 用GPU输出hello world

语法点：

1. 修饰符`__global__`告诉编译器这个函数将会从CPU中调用，然后在GPU上执行。

2. 三重尖括号`内核函数 <<<a, b>>>`意味着从主线程到设备端代码的调用。
   -  a 表示启动的线程块数（number of blocks）。
   - b 表示每个线程块中的线程数（number of threads per block）。

CUDA编程结构包括5个主要步骤:

1. 分配GPU内存。
2. 从CPU内存中拷贝数据到GPU内存。
3. 调用CUDA内核函数来完成程序指定的运算。(内核函数)
4. 将数据从GPU拷回CPU内存。
5. 释放GPU内存空间。

### 1.4 课后习题

2. cudaDeviceReset 会等待gpu把信息返回cpu
3. cudaDeviceSynchronize 与 cudaDeviceReset 等效
4. 使用变量 threadIdx 可以获取线程号

## CH2 CUDA 编程模型

### 2.1 CUDA编程模型概述

#### 2.1.1 CUDA编程模型

一个典型的CUDA程序实现流程遵循以下模式

1. 把数据从CPU内存拷贝到GPU内存
2. 调用核函数对存储在GPU内存中的数据进行操作
3. 将数据从GPU内存传送回到CPU内存

### 2.1.2 内存管理

常用函数：

|函数|说明|
|-|-|
|cudaError_t cudaMalloc(void** devPtr, size_t size)||
|cudaError_t cudaMemcoy(void* dst, const void* src, size_t count, cudaMemcpyKind kind)|1. 阻塞式2.kind指定方向|
|cudaGetErrorString()|将运行时错误转为字符串|

gpu线程、线程块、网格之间的关系：

- 网格：一个内核启动所产生的所有线程，共享相同的全局内存空间
- 线程块：不同块内的线程不能协作
- 线程：依靠以下两个坐标变量来区分彼此`blockIdx（线程块在线程格内的索引）`,`threadIdx（块内的线程索引）`


```txt
+---------------------+        +---------------------+
|  Thread Block (1)   |        |  Thread Block (2)  |
|                     |        |                     |
|  +---------------+  |        |  +---------------+  |
|  |   Thread (1)  |  |        |  |   Thread (1)  |  |
|  |               |  |        |  |               |  |
|  +---------------+  |        |  +---------------+  |
|  |   Thread (2)  |  |        |  |   Thread (2)  |  |
|  |               |  |        |  |               |  |
|  +---------------+  |        |  +---------------+  |
|                     |        |                     |
|  +---------------+  |        |  +---------------+  |
|  |   Thread (3)  |  |        |  |   Thread (3)  |  |
|  |               |  |        |  |               |  |
|  +---------------+  |        |  +---------------+  |
|  |   Thread (4)  |  |        |  |   Thread (4)  |  |
|  |               |  |        |  |               |  |
|  +---------------+  |        |  +---------------+  |
+---------------------+        +---------------------+

           +---------------------+
           |       Grid          |
           |                     |
           |  +---------------+  |
           |  | Thread Block  |  |
           |  |               |  |
           |  +---------------+  |
           |                     |
           |  +---------------+  |
           |  | Thread Block  |  |
           |  |               |  |
           |  +---------------+  |
           +---------------------+

```

```txt
          +-----------------------+
          |                       |
          |      Host Memory      |
          |                       |
          +-----------------------+   CPU
----------------------------------------------
                      |
                      |
                      |PCIE总线
                      |
                      |
----------------------------------------------
                                        GPU
          +-----------------------+
          |                       |
          |    Global Memory      |
          |    (GPU Memory)       |
          |                       |
          |                       |
          +-----------------------+
                  /        \
                 /          \
                /            \
               /              \
              /                \
             /                  \
            /                    \
           /                      \
          /                        \
         /                          \
        /                            \
       /                              \
      /                                \
     /                                  \
    /                                    \
   /                                      \
  /                                        \
 /                                          \
+-----------------------+    +-----------------------+
| Shared Memory (Block) |    | Shared Memory (Block) |
|                       |    |                       |
|                       |    |                       |
|                       |    |                       |
+-----------------------+    +-----------------------+
Thread Block (线程块)          Thread Block (线程块)

```

核函数的限制：

- 只能访问设备内存
- 必须具有void返回类型
- 不支持可变数量的参数
- 不支持静态变量
- 显示异步行为

debug:
1. 设备端的核函数中使用printf函数
2. 可以将执行参数设置为<<<1，1>>>，因此强制用一个块和一个线程执行核函数，这模拟了串行执行程序

错误处理：

```c
#include<stdio.h>

#define CHECK(call)\
{\
    const cudaError_t error = call;\
    if(error != cudaSuccess){\
        printf("Error: %s:%d, ", __FILE__, __LINE__);\
        printf("code:%d, reason:%s\n", error, cudaGetErrorString(error));\
        exit(1);\
    }\
}

int main(){
    // 检查点
    // CHECK(cudaMemcpy(……))
    return 0;
}
```

nvprof使用：`nvprof ./[你的程序]`